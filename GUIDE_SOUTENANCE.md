# üéØ Guide de Soutenance Technique - Bank Churn MLOps

## üìã Structure de Pr√©sentation (15-20 minutes)

---

## üé¨ PARTIE 1 : INTRODUCTION (2 min)

### Slide 1 : Contexte et Probl√©matique

**Ce que vous dites :**
> "Bonjour, je vais vous pr√©senter un projet MLOps complet : une API de pr√©diction de d√©faillance client (churn) pour une banque, d√©ploy√©e en production sur Azure avec un pipeline CI/CD automatis√©."

**Points cl√©s √† mentionner :**
- ‚úÖ Probl√®me business r√©el : r√©duire le churn client
- ‚úÖ Solution technique : ML + DevOps = MLOps
- ‚úÖ D√©ploiement production-ready sur le cloud Azure

**Pourquoi c'est impressionnant :**
- Vous montrez que vous comprenez le cycle complet ML ‚Üí Production
- Vous avez choisi une probl√©matique business r√©elle

---

## üé¨ PARTIE 2 : ARCHITECTURE GLOBALE (3 min)

### Slide 2 : Vue d'ensemble de l'architecture

**Ce que vous dites :**
> "Voici l'architecture compl√®te de mon syst√®me. Elle suit les meilleures pratiques MLOps avec 5 composants principaux :"

**Dessinez ou montrez ce sch√©ma :**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dataset   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Training    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   MLflow   ‚îÇ
‚îÇ  bank_churn ‚îÇ     ‚îÇ   Script     ‚îÇ     ‚îÇ  Registry  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   GitHub    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   GitHub    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Docker    ‚îÇ
‚îÇ   Repo      ‚îÇ     ‚îÇ   Actions    ‚îÇ     ‚îÇ   Image     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Azure     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Azure     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   FastAPI   ‚îÇ
‚îÇ Container   ‚îÇ     ‚îÇ Container   ‚îÇ     ‚îÇ    API      ‚îÇ
‚îÇ  Registry   ‚îÇ     ‚îÇ    Apps     ‚îÇ     ‚îÇ Production  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Points techniques √† expliquer :**
1. **Pipeline automatis√©** : Code ‚Üí Tests ‚Üí Build ‚Üí Deploy
2. **Conteneurisation** : Portabilit√© et reproductibilit√©
3. **Cloud-native** : Scalabilit√© et haute disponibilit√©

**Phrase cl√© :**
> "Chaque commit sur la branche main d√©clenche automatiquement un rebuild et un red√©ploiement, garantissant que la production est toujours √† jour."

---

## üé¨ PARTIE 3 : D√âMONSTRATION LIVE (5-7 min)

### D√©mo 1 : Le Mod√®le ML (2 min)

**Ce que vous faites :**
```bash
# Ouvrez votre terminal et montrez :
python train_model.py
```

**Ce que vous expliquez pendant l'ex√©cution :**
> "Je vais entra√Æner un mod√®le Random Forest sur 10 000 clients. Le script utilise MLflow pour tracker automatiquement toutes les m√©triques : accuracy, precision, recall, F1-score, et ROC-AUC."

**Montrez ensuite :**
```bash
# Ouvrez MLflow UI
mlflow ui --port 5000
```

**Points √† mettre en avant :**
- ‚úÖ **Reproductibilit√©** : Tous les param√®tres sont track√©s
- ‚úÖ **Versioning** : Chaque run est sauvegard√© avec un ID unique
- ‚úÖ **M√©triques** : Visualisation automatique des performances
- ‚úÖ **Artifacts** : Matrice de confusion et feature importance sauvegard√©es

**Phrase cl√© :**
> "MLflow me permet de comparer diff√©rentes versions de mod√®les et de choisir le meilleur pour la production."

---

### D√©mo 2 : L'API FastAPI (2 min)

**Ce que vous faites :**
```bash
# D√©marrez l'API localement
uvicorn app.main:app --reload
```

**Ouvrez dans le navigateur :**
```
http://localhost:8000/docs
```

**Ce que vous expliquez :**
> "Voici la documentation interactive de mon API. FastAPI g√©n√®re automatiquement cette interface Swagger. Je peux tester directement les endpoints."

**Faites une pr√©diction en direct :**
1. Cliquez sur `/predict` ‚Üí "Try it out"
2. Utilisez les donn√©es d'exemple
3. Cliquez sur "Execute"

**Montrez la r√©ponse :**
```json
{
  "churn_probability": 0.7234,
  "prediction": 1,
  "risk_level": "High"
}
```

**Points √† mettre en avant :**
- ‚úÖ **Validation automatique** : Pydantic v√©rifie les types et contraintes
- ‚úÖ **Documentation auto** : Pas besoin de documenter manuellement
- ‚úÖ **Endpoints multiples** : `/predict` pour un client, `/predict/batch` pour plusieurs
- ‚úÖ **Health check** : `/health` pour v√©rifier l'√©tat de l'API

**Phrase cl√© :**
> "L'API est production-ready avec validation robuste, gestion d'erreurs, et documentation automatique."

---

### D√©mo 3 : Docker et Conteneurisation (1 min)

**Ce que vous faites :**
```bash
# Montrez le Dockerfile
cat Dockerfile

# Build l'image
docker build -t churn-api:v1 .

# Testez le conteneur
docker run -p 8000:8000 churn-api:v1
```

**Ce que vous expliquez :**
> "J'ai conteneuris√© mon application avec Docker. Cela garantit que l'application fonctionne de la m√™me mani√®re sur ma machine, dans les tests CI/CD, et en production sur Azure."

**Points √† mettre en avant :**
- ‚úÖ **Reproductibilit√©** : M√™me environnement partout
- ‚úÖ **Isolation** : Pas de conflits de d√©pendances
- ‚úÖ **Portabilit√©** : Fonctionne sur n'importe quelle plateforme

---

### D√©mo 4 : Pipeline CI/CD (2 min)

**Ce que vous faites :**
1. Ouvrez GitHub ‚Üí Actions
2. Montrez un run r√©cent du pipeline

**Ce que vous expliquez :**
> "Voici mon pipeline CI/CD automatis√©. Il se d√©clenche √† chaque commit sur la branche main."

**Montrez les 3 jobs :**

1. **Job Test** :
   - Tests sur Python 3.9, 3.10, 3.11
   - Linting avec flake8
   - Coverage avec pytest
   - ‚úÖ "Tous les tests passent"

2. **Job Build & Deploy** :
   - Build Docker avec cache
   - Push vers GitHub Container Registry
   - D√©ploiement automatique sur Azure
   - Health check post-d√©ploiement
   - ‚úÖ "D√©ploiement r√©ussi"

3. **Job Notify** :
   - Notification de succ√®s/√©chec

**Phrase cl√© :**
> "En moins de 5 minutes, mon code passe automatiquement des tests √† la production, sans intervention manuelle."

---

### D√©mo 5 : Production sur Azure (1 min)

**Ce que vous faites :**
```bash
# Montrez l'URL de production
# (depuis azure-deploy-info.txt ou le portail Azure)
```

**Testez l'API en production :**
```bash
curl https://votre-app.azurecontainerapps.io/health
curl -X POST https://votre-app.azurecontainerapps.io/predict \
  -H "Content-Type: application/json" \
  -d '{"CreditScore": 700, "Age": 35, ...}'
```

**Ce que vous expliquez :**
> "Mon API est d√©ploy√©e en production sur Azure Container Apps. Elle est accessible publiquement, scalable automatiquement, et monitor√©e."

**Points √† mettre en avant :**
- ‚úÖ **Haute disponibilit√©** : Azure g√®re les red√©marrages automatiques
- ‚úÖ **Scalabilit√©** : Auto-scaling selon la charge
- ‚úÖ **S√©curit√©** : HTTPS automatique, isolation r√©seau

---

## üé¨ PARTIE 4 : CHOIX TECHNIQUES ET JUSTIFICATIONS (3 min)

### Pourquoi ces technologies ?

**1. FastAPI vs Flask :**
> "J'ai choisi FastAPI car c'est plus rapide (bas√© sur Starlette/Uvicorn), avec validation automatique des donn√©es via Pydantic, et documentation auto-g√©n√©r√©e. C'est la r√©f√©rence pour les APIs ML modernes."

**2. MLflow vs autres solutions :**
> "MLflow est l'outil standard de l'industrie pour le ML lifecycle. Il offre tracking, registry, et d√©ploiement int√©gr√©s. C'est open-source et support√© par Databricks."

**3. Azure Container Apps vs autres services :**
> "Azure Container Apps est serverless, donc je ne paie que ce que j'utilise. C'est plus simple que Kubernetes pour mon cas d'usage, avec auto-scaling et HTTPS int√©gr√©s."

**4. GitHub Actions vs autres CI/CD :**
> "GitHub Actions est int√©gr√© nativement avec GitHub, gratuit pour les repos publics, et tr√®s flexible. Il supporte Docker et Azure nativement."

**5. Docker :**
> "Docker est devenu le standard de l'industrie pour la conteneurisation. Il garantit la reproductibilit√© et simplifie le d√©ploiement."

---

## üé¨ PARTIE 5 : M√âTRIQUES ET R√âSULTATS (2 min)

### Performance du Mod√®le

**Montrez les m√©triques MLflow :**
- Accuracy : ~0.85-0.90
- Precision : ~0.80-0.85
- Recall : ~0.75-0.80
- F1-Score : ~0.77-0.82
- ROC-AUC : ~0.85-0.90

**Ce que vous dites :**
> "Mon mod√®le Random Forest atteint une accuracy de 85-90%, ce qui est excellent pour un probl√®me de classification binaire. Le ROC-AUC de 0.85-0.90 montre une bonne capacit√© de discrimination."

### Performance de l'API

**M√©triques √† mentionner :**
- ‚úÖ Temps de r√©ponse : < 100ms par pr√©diction
- ‚úÖ Disponibilit√© : 99.9% (gr√¢ce √† Azure)
- ‚úÖ Throughput : Capable de g√©rer des centaines de requ√™tes/seconde
- ‚úÖ Latence : < 50ms pour une pr√©diction simple

**Phrase cl√© :**
> "L'API r√©pond en moins de 100ms, ce qui est acceptable pour une application temps r√©el."

---

## üé¨ PARTIE 6 : BONNES PRATIQUES MLOPS (2 min)

### Ce que vous avez impl√©ment√©

**1. Versioning :**
- ‚úÖ Code versionn√© avec Git
- ‚úÖ Mod√®les versionn√©s avec MLflow
- ‚úÖ Images Docker tagu√©es

**2. Tests :**
- ‚úÖ Tests unitaires (pytest)
- ‚úÖ Tests d'int√©gration
- ‚úÖ Validation des mod√®les Pydantic
- ‚úÖ Coverage > 80%

**3. CI/CD :**
- ‚úÖ Pipeline automatis√©
- ‚úÖ Tests avant d√©ploiement
- ‚úÖ D√©ploiement automatique
- ‚úÖ Health checks

**4. Monitoring :**
- ‚úÖ Logs structur√©s
- ‚úÖ Health endpoints
- ‚úÖ M√©triques de performance

**5. Documentation :**
- ‚úÖ Documentation API auto-g√©n√©r√©e
- ‚úÖ README (√† cr√©er)
- ‚úÖ Commentaires dans le code

**Phrase cl√© :**
> "J'ai suivi les meilleures pratiques MLOps pour garantir la qualit√©, la reproductibilit√©, et la maintenabilit√© du syst√®me."

---

## üé¨ PARTIE 7 : D√âFIS ET SOLUTIONS (2 min)

### D√©fis rencontr√©s

**1. Gestion des d√©pendances :**
> "J'ai rencontr√© des probl√®mes de compatibilit√© entre les versions de packages. Solution : J'ai utilis√© un environnement virtuel et fix√© les versions dans requirements.txt."

**2. D√©ploiement Azure :**
> "Les noms de ressources Azure doivent √™tre uniques globalement. Solution : J'ai utilis√© des noms al√©atoires et des variables d'environnement."

**3. Tests dans le pipeline :**
> "Les tests n√©cessitent le mod√®le charg√©. Solution : J'ai utilis√© des mocks dans les tests unitaires et je charge le vrai mod√®le seulement dans les tests d'int√©gration."

**4. Gestion des secrets :**
> "Les credentials Azure ne doivent jamais √™tre commit√©s. Solution : J'ai utilis√© GitHub Secrets pour stocker les credentials de mani√®re s√©curis√©e."

**Phrase cl√© :**
> "Ces d√©fis m'ont permis d'apprendre les bonnes pratiques de s√©curit√© et de gestion de configuration en production."

---

## üé¨ PARTIE 8 : AM√âLIORATIONS FUTURES (1 min)

### Ce qui pourrait √™tre ajout√©

**1. Monitoring avanc√© :**
- Application Insights pour le tracking d√©taill√©
- Alertes automatiques en cas d'erreur
- Dashboards de m√©triques

**2. Cache des pr√©dictions :**
- LRU cache pour les pr√©dictions fr√©quentes
- R√©duction de la latence et des co√ªts

**3. A/B Testing :**
- Tester plusieurs versions de mod√®les
- Routage intelligent selon les performances

**4. Data Drift Detection :**
- D√©tecter les changements dans les donn√©es d'entr√©e
- Alerter si le mod√®le devient obsol√®te

**5. Auto-retraining :**
- R√©entra√Ænement automatique p√©riodique
- D√©ploiement automatique du nouveau mod√®le

**Phrase cl√© :**
> "Ces am√©liorations permettraient de rendre le syst√®me encore plus robuste et autonome."

---

## üé¨ PARTIE 9 : CONCLUSION (1 min)

### R√©sum√©

**Ce que vous dites :**
> "Pour conclure, j'ai d√©velopp√© un syst√®me MLOps complet qui va de l'entra√Ænement du mod√®le √† la production, avec un pipeline CI/CD automatis√©. Le syst√®me est scalable, maintenable, et suit les meilleures pratiques de l'industrie."

### Points forts √† rappeler

1. ‚úÖ **Architecture compl√®te** : ML ‚Üí API ‚Üí Docker ‚Üí Cloud ‚Üí CI/CD
2. ‚úÖ **Automatisation** : Pipeline enti√®rement automatis√©
3. ‚úÖ **Production-ready** : Tests, monitoring, documentation
4. ‚úÖ **Best practices** : Versioning, s√©curit√©, reproductibilit√©

**Phrase de cl√¥ture :**
> "Ce projet m'a permis de ma√Ætriser l'ensemble du cycle de vie MLOps, de la recherche √† la production, en suivant les standards de l'industrie."

---

## üí° ASTUCES POUR IMPRESSIONNER

### 1. Utilisez des m√©taphores simples

**Exemple :**
> "MLflow, c'est comme Git pour les mod√®les ML : √ßa track les versions, les param√®tres, et les performances."

### 2. Montrez votre compr√©hension du business

**Exemple :**
> "Pour une banque, r√©duire le churn de 5% peut repr√©senter des millions d'euros √©conomis√©s. Mon API permet d'identifier les clients √† risque en temps r√©el."

### 3. Mentionnez les co√ªts

**Exemple :**
> "Avec Azure Container Apps, je paie seulement pour les requ√™tes trait√©es. Pour 1000 pr√©dictions par jour, le co√ªt est d'environ 5‚Ç¨/mois."

### 4. Montrez votre capacit√© √† apprendre

**Exemple :**
> "J'ai d√©couvert MLflow pendant ce projet. C'est maintenant mon outil de r√©f√©rence pour tous mes projets ML."

### 5. Pr√©parez des r√©ponses aux questions difficiles

**Questions probables et r√©ponses :**

**Q : "Pourquoi Random Forest et pas un mod√®le plus moderne comme XGBoost ?"**
> R : "Random Forest est un excellent choix pour commencer car il est interpr√©table, robuste aux outliers, et ne n√©cessite pas beaucoup de tuning. XGBoost serait la prochaine √©tape pour am√©liorer les performances."

**Q : "Comment g√©rez-vous les donn√©es sensibles (RGPD) ?"**
> R : "Les donn√©es sont anonymis√©es et ne contiennent pas d'informations personnelles identifiables. Pour la production, il faudrait ajouter le chiffrement et la gestion du consentement."

**Q : "Que se passe-t-il si le mod√®le devient obsol√®te ?"**
> R : "C'est exactement pourquoi j'ai mentionn√© le data drift detection dans les am√©liorations futures. Pour l'instant, je r√©entra√Æne manuellement le mod√®le p√©riodiquement et le red√©ploie via le pipeline CI/CD."

**Q : "Comment testez-vous la scalabilit√© ?"**
> R : "Azure Container Apps g√®re automatiquement le scaling. Je pourrais faire un load test avec Apache Bench ou Locust pour valider les performances sous charge."

---

## üéØ CHECKLIST AVANT LA SOUTENANCE

### Pr√©paration technique

- [ ] Tester toutes les d√©mos en local
- [ ] V√©rifier que l'API en production fonctionne
- [ ] Pr√©parer des donn√©es d'exemple pour les tests
- [ ] V√©rifier que MLflow UI d√©marre correctement
- [ ] Tester le pipeline CI/CD (faire un petit commit)
- [ ] Pr√©parer des captures d'√©cran de secours

### Pr√©paration pr√©sentation

- [ ] Cr√©er des slides (PowerPoint/Google Slides)
- [ ] Pr√©parer le script de pr√©sentation
- [ ] Chronom√©trer la pr√©sentation (15-20 min)
- [ ] Pr√©parer les r√©ponses aux questions
- [ ] R√©p√©ter plusieurs fois

### Mat√©riel

- [ ] Ordinateur avec tous les outils install√©s
- [ ] Connexion Internet stable
- [ ] Acc√®s √† GitHub et Azure
- [ ] Terminal et navigateur pr√™ts
- [ ] Slides en backup (USB/cl√©)

---

## üìä TEMPLATE DE SLIDES

### Slide 1 : Titre
```
Bank Churn Prediction API
Projet MLOps avec Azure

[Votre nom]
[Date]
```

### Slide 2 : Architecture
```
[Sch√©ma de l'architecture]
```

### Slide 3 : Stack Technique
```
- Python 3.9
- FastAPI
- Scikit-learn (Random Forest)
- MLflow
- Docker
- Azure Container Apps
- GitHub Actions
```

### Slide 4 : R√©sultats
```
- Accuracy : 85-90%
- ROC-AUC : 0.85-0.90
- Latence API : < 100ms
- Disponibilit√© : 99.9%
```

### Slide 5 : Pipeline CI/CD
```
[Sch√©ma du pipeline]
```

### Slide 6 : D√©monstration
```
[Lien vers l'API en production]
```

### Slide 7 : Am√©liorations Futures
```
- Monitoring avanc√©
- Cache des pr√©dictions
- Data drift detection
- Auto-retraining
```

### Slide 8 : Conclusion
```
Merci pour votre attention !
Questions ?
```

---

## üé§ TON ET ATTITUDE

### √Ä faire ‚úÖ

- **Soyez enthousiaste** : Montrez votre passion pour le projet
- **Parlez clairement** : Articulez bien, parlez √† un rythme mod√©r√©
- **Souriez** : Montrez que vous √™tes √† l'aise
- **Regardez votre auditoire** : Ne fixez pas seulement l'√©cran
- **Admettez vos limites** : "Je n'ai pas encore impl√©ment√© X, mais je pr√©vois de le faire"

### √Ä √©viter ‚ùå

- Ne pas lire vos slides mot √† mot
- Ne pas vous excuser pour des choses mineures
- Ne pas √™tre trop technique sans expliquer
- Ne pas d√©passer le temps imparti
- Ne pas paniquer si quelque chose ne fonctionne pas (avoir un plan B)

---

## üöÄ PHRASES MAGIQUES √Ä RETENIR

1. **"J'ai suivi les meilleures pratiques MLOps de l'industrie"**
2. **"Le syst√®me est enti√®rement automatis√© de bout en bout"**
3. **"Chaque commit d√©clenche automatiquement un rebuild et un red√©ploiement"**
4. **"L'API est production-ready avec tests, monitoring et documentation"**
5. **"Ce projet m'a permis de ma√Ætriser l'ensemble du cycle de vie MLOps"**

---

## üìù NOTES FINALES

**Rappelez-vous :**
- Votre professeur veut voir que vous **comprenez** ce que vous avez fait
- Montrez que vous pouvez **justifier vos choix techniques**
- D√©montrez que vous avez **appris** et que vous pouvez **am√©liorer**
- Restez **humble** mais **confiant**

**Bonne chance pour votre soutenance ! üéâ**

---

*Guide cr√©√© pour : Bank Churn MLOps Project*
*Date : 2025*
